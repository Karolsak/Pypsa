{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to add load, generators, missing lines and transformers to SciGRID\n",
    "\n",
    "\n",
    "# WARNING: This script is no longer supported, since the libraries and data no longer exist in their former versions\n",
    "\n",
    "# It is kept here for interest's sake\n",
    "\n",
    "# See https://github.com/PyPSA/pypsa-eur for a newer model that covers all of Europe\n",
    "\n",
    "\n",
    "This Jupyter Notebook is also available to download at: <http://www.pypsa.org/examples/add_load_gen_trafos_to_scigrid.ipynb>  and can be viewed as an HTML page at: http://pypsa.org/examples/add_load_gen_trafos_to_scigrid.html.\n",
    "\n",
    "This script does some post-processing on the original SciGRID dataset version 0.2 and then adds load, generation, transformers and missing lines to the SciGRID dataset.\n",
    "\n",
    "The intention is to create a model of the German electricity system that is transparent in the sense that all steps from openly-available raw data to the final model can be followed. The model is NOT validated and may contain errors.\n",
    "\n",
    "Some of the libraries used for attaching the load and generation are not on github, but can be downloaded at\n",
    "\n",
    "http://fias.uni-frankfurt.de/~hoersch/\n",
    "\n",
    "The intention is to release these as free software soon. We cannot guarantee to support you when using these libraries.\n",
    "\n",
    "\n",
    "\n",
    "## Data sources\n",
    "\n",
    "Grid: based on [SciGRID](http://scigrid.de/) Version 0.2 which is based on [OpenStreetMap](http://www.openstreetmap.org/).\n",
    "\n",
    "Load size and location: based on Landkreise (NUTS 3) GDP and population.\n",
    "\n",
    "Load time series: from ENTSO-E hourly data, scaled up uniformly by factor 1.12 (a simplification of the methodology in Schumacher, Hirth (2015)).\n",
    "\n",
    "Conventional power plant capacities and locations: BNetzA list.\n",
    "\n",
    "Wind and solar capacities and locations: EEG Stammdaten, based on  http://www.energymap.info/download.html, which represents capacities at the end of 2014. Units without PLZ are removed.\n",
    "\n",
    "Wind and solar time series: REatlas, Andresen et al, \"Validation of Danish wind time series from a new global renewable energy atlas for energy system analysis,\" Energy 93 (2015) 1074 - 1088.\n",
    "\n",
    "NB:\n",
    "\n",
    "All times in the dataset are UTC.\n",
    "\n",
    "Where SciGRID nodes have been split into 220kV and 380kV substations, all load and generation is attached to the 220kV substation.\n",
    "\n",
    "## Warning\n",
    "\n",
    "This dataset is ONLY intended to demonstrate the capabilities of PyPSA and is NOT (yet) accurate enough to be used for research purposes.\n",
    "\n",
    "Known problems include:\n",
    "\n",
    "i) Rough approximations have been made for missing grid data, e.g. 220kV-380kV transformers and connections between close sub-stations missing from OSM.\n",
    "\n",
    "ii) There appears to be some unexpected congestion in parts of the network, which may mean for example that the load attachment method (by Voronoi cell overlap with Landkreise) isn't working, particularly in regions with a high density of substations.\n",
    "\n",
    "iii) Attaching power plants to the nearest high voltage substation may not reflect reality.\n",
    "\n",
    "iv) There is no proper n-1 security in the calculations - this can either be simulated with a blanket e.g. 70% reduction in thermal limits (as done here) or a proper security constrained OPF (see e.g.  <http://www.pypsa.org/examples/scigrid-sclopf.ipynb>).\n",
    "\n",
    "v) The borders and neighbouring countries are not represented.\n",
    "\n",
    "vi) Hydroelectric power stations are not modelled accurately.\n",
    "\n",
    "viii) The marginal costs are illustrative, not accurate.\n",
    "\n",
    "ix) Only the first day of 2011 is in the github dataset, which is not representative. The full year of 2011 can be downloaded at <http://www.pypsa.org/examples/scigrid-with-load-gen-trafos-2011.zip>.\n",
    "\n",
    "x) The ENTSO-E total load for Germany may not be scaled correctly; it is scaled up uniformly by factor 1.12 (a simplification of the methodology in Schumacher, Hirth (2015), which suggests monthly factors).\n",
    "\n",
    "xi) Biomass from the EEG Stammdaten are not read in at the moment.\n",
    "\n",
    "xii) Power plant start up costs, ramping limits/costs, minimum loading rates are not considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the code as Python 3 compatible as possible\n",
    "from __future__ import print_function, division,absolute_import\n",
    "\n",
    "import pypsa\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from six import iteritems\n",
    "from six.moves import range\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the raw SciGRID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may have to adjust this path to where \n",
    "#you downloaded the github repository\n",
    "#https://github.com/PyPSA/PyPSA\n",
    "\n",
    "folder_prefix =  \"../scigrid-de/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that some columns have 'quotes because of fields containing commas'\n",
    "vertices = pd.read_csv(folder_prefix+\"scigrid-151109/vertices_de_power_151109.csvdata\",sep=\",\",quotechar=\"'\",index_col=0)\n",
    "\n",
    "vertices.rename(columns={\"lon\":\"x\",\"lat\":\"y\",\"name\":\"osm_name\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vertices[\"voltage\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv(folder_prefix+\"scigrid-151109/links_de_power_151109.csvdata\",sep=\",\",quotechar=\"'\",index_col=0)\n",
    "links.rename(columns={\"v_id_1\":\"bus0\",\"v_id_2\":\"bus1\",\"name\":\"osm_name\"},inplace=True)\n",
    "\n",
    "links[\"cables\"].fillna(3,inplace=True)\n",
    "links[\"wires\"].fillna(2,inplace=True)\n",
    "\n",
    "links[\"length\"] = links[\"length_m\"]/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(links[\"voltage\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the DC lines\n",
    "\n",
    "for voltage in [300000,400000,450000]:\n",
    "    links.drop(links[links.voltage == voltage].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build the network\n",
    "\n",
    "network = pypsa.Network()\n",
    "\n",
    "pypsa.io.import_components_from_dataframe(network,vertices,\"Bus\")\n",
    "\n",
    "pypsa.io.import_components_from_dataframe(network,links,\"Line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add specific missing AC lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add AC lines known to be missing in SciGRID                                                                                                             \n",
    "# E.g. lines missing because of OSM mapping errors.                                                                                                       \n",
    "# This is no systematic list, just what we noticed;                                                                                                       \n",
    "# please tell SciGRID and/or Tom Brown (brown@fias.uni-frankfurt.de)                                                                                      \n",
    "# if you know of more examples                                                                                                                            \n",
    "\n",
    "columns = [\"bus0\",\"bus1\",\"wires\",\"cables\",\"voltage\"]\n",
    "\n",
    "data = [[\"100\",\"255\",2,6,220000], # Niederstedem to Wengerohr                                                                                             \n",
    "        [\"384\",\"351\",4,6,380000], # Raitersaich to Ingolstadt                                                                                             \n",
    "        [\"351\",\"353\",4,6,380000], # Ingolstadt to Irsching                                                                                                \n",
    "        ]\n",
    "\n",
    "last_scigrid_line = int(network.lines.index[-1])\n",
    "\n",
    "index = [str(i) for i in range(last_scigrid_line+1,last_scigrid_line+1 + len(data))]\n",
    "\n",
    "missing_lines = pd.DataFrame(data,index,columns)\n",
    "\n",
    "#On average, SciGRID lines are 25% longer than the direct distance\n",
    "length_factor = 1.25\n",
    "\n",
    "missing_lines[\"length\"] = [length_factor*pypsa.geo.haversine(network.buses.loc[r.bus0,[\"x\",\"y\"]],network.buses.loc[r.bus1,[\"x\",\"y\"]])[0,0] for i,r in missing_lines.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pypsa.io.import_components_from_dataframe(network,missing_lines,\"Line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.lines.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the voltage of the buses by the lines which end there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.lines.voltage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buses_by_voltage = {}\n",
    "\n",
    "for voltage in network.lines.voltage.value_counts().index:\n",
    "    buses_by_voltage[voltage] = set(network.lines[network.lines.voltage == voltage].bus0)\\\n",
    "                                | set(network.lines[network.lines.voltage == voltage].bus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give priority to 380 kV\n",
    "network.buses[\"v_nom\"] = 380\n",
    "network.buses.loc[buses_by_voltage[220000],\"v_nom\"] = 220\n",
    "network.buses.loc[buses_by_voltage[380000],\"v_nom\"] = 380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.buses.v_nom.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect buses which are < 850m apart\n",
    "\n",
    "There are pairs of buses less than 850m apart which are not connected in SciGRID, but clearly connected in OpenStreetMap (OSM).\n",
    "\n",
    "The reason is that the relations for connections between close substations do not appear in OSM.\n",
    "\n",
    "Here they are connected with 2 circuits of the appropriate voltage level (an asumption).\n",
    "\n",
    "850m is chosen as a limit based on manually looking through the examples.\n",
    "\n",
    "The example 46-48 (Marzahn) at 892 m apart is the first example of close substations which are not connected in reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distances for unique pairs\n",
    "\n",
    "pairs = pd.Series()\n",
    "\n",
    "for i,u in enumerate(network.buses.index):\n",
    "    vs = network.buses[[\"x\",\"y\"]].iloc[i+1:]\n",
    "    distance_km = pypsa.geo.haversine(vs,network.buses.loc[u,[\"x\",\"y\"]])\n",
    "\n",
    "    to_add = pd.Series(data=distance_km[:,0],index=[(u,v) for v in vs.index])\n",
    "    \n",
    "    pairs = pd.concat((pairs,to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.sort_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine topology so we can look what's actually connected\n",
    "network.determine_network_topology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example all substations which are close to                                                                                                              \n",
    "# each other geographically by not connected in network.adj                                                                                               \n",
    "\n",
    "start = 0  #km                                                                                                                                            \n",
    "stop = 1 #km                                                                                                                                              \n",
    "\n",
    "for (u,v),dist in pairs.sort_values().iteritems():\n",
    "\n",
    "    if dist < start:\n",
    "        continue\n",
    "\n",
    "    #only go up to pairs stop km apart                                                                                                                    \n",
    "    if dist > stop:\n",
    "        break\n",
    "\n",
    "    #ignore if they're already connected                                                                                                                  \n",
    "    if u in network.graph().adj[v]:\n",
    "        continue\n",
    "\n",
    "\n",
    "    print(u,v,dist)\n",
    "\n",
    "    u_x = network.buses.at[u,\"x\"]\n",
    "    u_y = network.buses.at[u,\"y\"]\n",
    "    v_x = network.buses.at[v,\"x\"]\n",
    "    v_y = network.buses.at[v,\"y\"]\n",
    "\n",
    "    #have a look what's going on in OSM                                                                                                                   \n",
    "    print(\"https://www.openstreetmap.org/#map=18/{}/{}\".format(u_y,u_x))\n",
    "    print(\"https://www.openstreetmap.org/#map=18/{}/{}\".format(v_y,v_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From examining the map, it seems that all cases where substations                                                                                       \n",
    "# are less than 850m apart are connected in reality                                                                                                       \n",
    "# The first one to fail is 46-48 (Marzahn) at 892 m                                                                                                       \n",
    "\n",
    "# Connect these substations                                                                                                                               \n",
    "\n",
    "limit = 0.85\n",
    "\n",
    "for (u,v),dist in pairs.sort_values().iteritems():\n",
    "\n",
    "    #only go up to pairs stop km apart                                                                                                                    \n",
    "    if dist > limit:\n",
    "        break\n",
    "\n",
    "    #ignore if they're already connected                                                                                                                  \n",
    "    if u in network.graph().adj[v]:\n",
    "        continue\n",
    "\n",
    "\n",
    "    kv_u = network.buses.at[u,\"v_nom\"]\n",
    "    kv_v = network.buses.at[v,\"v_nom\"]\n",
    "\n",
    "    print(u,v,dist,kv_u,kv_v)\n",
    "    \n",
    "    last_scigrid_line = int(network.lines.index[-1])\n",
    "    \n",
    "    voltage = max(kv_u,kv_v)*1000\n",
    "    \n",
    "    wires = {220000 : 2, 380000 : 4}[voltage]\n",
    "    \n",
    "    cables = 6\n",
    "    \n",
    "    df = pd.DataFrame([[u,v,length_factor*dist,wires,cables,voltage]],columns=[\"bus0\",\"bus1\",\"length\",\"wires\",\"cables\",\"voltage\"],index=[str(last_scigrid_line+1)])\n",
    "\n",
    "    pypsa.io.import_components_from_dataframe(network,df,\"Line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split buses with more than one voltage; add trafos between\n",
    "\n",
    "This code splits the buses where you have 220 and 380 kV lines landing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.lines.voltage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buses_by_voltage = {}\n",
    "\n",
    "for voltage in network.lines.voltage.value_counts().index:\n",
    "    buses_by_voltage[voltage] = set(network.lines[network.lines.voltage == voltage].bus0)\\\n",
    "                                | set(network.lines[network.lines.voltage == voltage].bus1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.buses.v_nom=380\n",
    "network.buses.loc[buses_by_voltage[220000],\"v_nom\"] = 220\n",
    "network.buses.loc[buses_by_voltage[380000],\"v_nom\"] = 380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = buses_by_voltage[220000] & buses_by_voltage[380000]\n",
    "len(overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build up new buses and transformers to import\n",
    "\n",
    "\n",
    "buses_to_split = [str(i) for i in sorted([int(item) for item in overlap])]\n",
    "buses_to_split_df = network.buses.loc[buses_to_split]\n",
    "\n",
    "buses_to_split_df.v_nom = 220\n",
    "\n",
    "buses_to_split_220kV = [name + \"_220kV\" for name in buses_to_split_df.index]\n",
    "\n",
    "buses_to_split_df.index = buses_to_split_220kV\n",
    "\n",
    "trafos_df = pd.DataFrame(index=buses_to_split)\n",
    "trafos_df[\"bus0\"] = buses_to_split\n",
    "trafos_df[\"bus1\"] = buses_to_split_220kV\n",
    "trafos_df[\"x\"] = 0.1\n",
    "#This high a nominal power is required for feasibility in LOPF\n",
    "trafos_df[\"s_nom\"] = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pypsa.io.import_components_from_dataframe(network,buses_to_split_df,\"Bus\")\n",
    "pypsa.io.import_components_from_dataframe(network,trafos_df,\"Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##reconnect lines to the correct voltage bus\n",
    "\n",
    "for line in network.lines.index:\n",
    "    bus0 = network.lines.at[line,\"bus0\"]\n",
    "    bus1 = network.lines.at[line,\"bus1\"]\n",
    "    v0 = network.buses.at[bus0,\"v_nom\"]\n",
    "    v1 = network.buses.at[bus1,\"v_nom\"]\n",
    "    v = network.lines.at[line,\"voltage\"]\n",
    "    if v0 != v/1000.:\n",
    "        print(line,v0,v)\n",
    "        network.lines.at[line,\"bus0\"] = bus0+\"_220kV\"\n",
    "    if v1 != v/1000.:\n",
    "        network.lines.at[line,\"bus1\"] = bus1+\"_220kV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the connected components\n",
    "\n",
    "network.determine_network_topology()\n",
    "\n",
    "\n",
    "#remove small isolated networks\n",
    "for sn in network.sub_networks.obj:\n",
    "    buses = sn.buses().index\n",
    "    branches = sn.branches().index\n",
    "    \n",
    "    if len(buses) < 5:\n",
    "        print(\"Dropping Sub-Network {} because it only has {} buses\".format(sn,len(buses)))\n",
    "        #print(buses.index)\n",
    "        #print(len(branches),branches.index)\n",
    "        for bus in buses:\n",
    "            network.remove(\"Bus\",bus)\n",
    "        for branch in branches:\n",
    "            network.remove(\"Line\",branch[1])\n",
    "    else:\n",
    "        print(\"Keeping Sub-Network {} because it has {} buses\".format(sn,len(buses)))\n",
    "\n",
    "#rebuild topology\n",
    "\n",
    "network.determine_network_topology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "colors = network.lines.voltage.map(lambda v: \"g\" if v == 220000 else \"r\" if v == 380000 else \"c\")\n",
    "network.plot(line_colors=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculate all electrical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.lines[\"type\"] = network.lines.voltage.map({220000 : \"Al/St 240/40 2-bundle 220.0\",\n",
    "                                                   380000 : \"Al/St 240/40 4-bundle 380.0\"})\n",
    "\n",
    "network.lines[\"num_parallel\"] = network.lines.cables/3.*network.lines.wires/network.lines.voltage.map({220000 : 2., 380000 : 4.})\n",
    "\n",
    "network.lines[\"s_nom\"] = 3.**0.5*network.lines.voltage/1000.*network.lines.num_parallel*network.lines.voltage.map({220000 : 2., 380000 : 4.})*0.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach the load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import FIAS libraries for attaching data\n",
    "\n",
    "#this script uses old versions of the FIAS libraries and \n",
    "#has not yet been updated to the new versions\n",
    "\n",
    "#the latest versions are available at\n",
    "#https://github.com/FRESNA/vresutils\n",
    "\n",
    "#if you get it working with the new versions, please\n",
    "#tell us! It shouldn't be too hard...\n",
    "\n",
    "try:\n",
    "    import vresutils, load\n",
    "except:\n",
    "    print(\"Oh dear! You don't have FIAS libraries, so you cannot add load :-(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vresutils import graph as vgraph\n",
    "from vresutils import shapes as vshapes\n",
    "from vresutils import grid as vgrid\n",
    "from vresutils import dispatch as vdispatch\n",
    "from shapely.geometry import Polygon\n",
    "from load import germany as DEload\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#bounding poly for Germany for the Voronoi - necessary\n",
    "#because some SciGRID points lie outside border vshapes.germany()\n",
    "poly = Polygon([[5.8,47.],[5.8,55.5],[15.2,55.5],[15.2,47.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_graph(network):\n",
    "    \"\"\"Generate a dummy graph to feed to the FIAS libraries.\n",
    "    It adds the \"pos\" attribute and removes the 380 kV duplicate\n",
    "    buses when the buses have been split, so that all load and generation\n",
    "    is attached to the 220kV bus.\"\"\"\n",
    "    \n",
    "    graph = pypsa.descriptors.OrderedGraph()\n",
    "    \n",
    "    graph.add_nodes_from([bus for bus in network.buses.index if bus not in buses_to_split])\n",
    "    \n",
    "    #add positions to graph for voronoi cell computation\n",
    "    for node in graph.nodes():\n",
    "        graph.node[node][\"pos\"] = np.array(network.buses.loc[node,[\"x\",\"y\"]],dtype=float)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = generate_dummy_graph(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.name = \"scigrid_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voronoi_partition(G, outline):\n",
    "    \"\"\"                                                                                                                                                   \n",
    "    For 2D-embedded graph `G`, within the boundary given by the shapely polygon                                                                           \n",
    "    `outline`, returns `G` with the Voronoi cell region as an additional node                                                                             \n",
    "    attribute.                                                                                                                                            \n",
    "    \"\"\"\n",
    "    #following line from vresutils.graph caused a bug\n",
    "    #G = polygon_subgraph(G, outline, copy=False)\n",
    "    points = list(vresutils.graph.get_node_attributes(G, 'pos').values())\n",
    "    regions = vresutils.graph.voronoi_partition_pts(points, outline, no_multipolygons=True)\n",
    "    nx.set_node_attributes(G, 'region', dict(zip(G.nodes(), regions)))\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi_partition(graph, poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: starts at midnight CET, 23:00 UTC\n",
    "load = DEload.timeseries(graph, years=[2011, 2012, 2013, 2014])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kill the Timezone information to avoid pandas bugs\n",
    "load.index = load.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the first year (in UTC time - we don't set time zone because of a Pandas bug)\n",
    "network.set_snapshots(pd.date_range(\"2011-01-01 00:00\",\"2011-12-31 23:00\",freq=\"H\"))\n",
    "\n",
    "print(network.snapshots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary load scaling factor for Germany load in relation to ENTSO-E hourly load\n",
    "#based roughly on Schumacher & Hirth (2015)\n",
    "#http://www.feem.it/userfiles/attach/20151191122284NDL2015-088.pdf\n",
    "#In principle rescaling should happen on a monthly basis\n",
    "\n",
    "load_factor = 1.12\n",
    "\n",
    "for bus in graph.nodes():\n",
    "    network.add(\"Load\",bus,bus=bus,\n",
    "                p_set = pd.Series(data=load_factor*1000*load.loc[network.snapshots,bus],index=network.snapshots))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(load.sum(axis=1)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_distribution = network.loads_t.p_set.loc[network.snapshots[0]].groupby(network.loads.bus).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.plot(bus_sizes=load_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_load = load.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_load = total_load.resample(\"M\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_load.plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach conventional generators from BNetzA list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vresutils import shapes as vshapes\n",
    "\n",
    "def read_kraftwerksliste(with_latlon=True):                                                                              \n",
    "                                                                                                              \n",
    "    kraftwerke = pd.read_csv('../../lib/vresutils/data/Kraftwerksliste_CSV_deCP850ed.csv',                                         \n",
    "                             delimiter=';', encoding='utf-8', thousands='.', decimal=',')                                \n",
    "    def sanitize_names(x):                                                                                               \n",
    "        try:                                                                                                             \n",
    "            x = x[:x.index('(')]                                                                                         \n",
    "        except ValueError:                                                                                               \n",
    "            pass                                                                                                         \n",
    "        return x.replace(u'\\n', u' ').strip()\n",
    "    kraftwerke.columns = kraftwerke.columns.map(sanitize_names)\n",
    "    \n",
    "    def sanitize_plz(x):\n",
    "        try:\n",
    "            x = x.strip()\n",
    "            if len(x) > 5:\n",
    "                x = x[:5]\n",
    "            return float(x)\n",
    "        except (ValueError, AttributeError):\n",
    "            return np.NAN\n",
    "    kraftwerke.PLZ = kraftwerke.PLZ.apply(sanitize_plz)\n",
    "    if with_latlon:\n",
    "        postcodes = {pc: sh.centroid\n",
    "                     for pc, sh in iteritems(vshapes.postcodeareas())\n",
    "                     if sh is not None}\n",
    "        kraftwerke['lon'] = kraftwerke.PLZ.map({pc: c.x for pc, c in iteritems(postcodes)})\n",
    "        kraftwerke['lat'] = kraftwerke.PLZ.map({pc: c.y for pc, c in iteritems(postcodes)})\n",
    "        #kraftwerke.dropna(subset=('lon','lat'), inplace=True)                                                           \n",
    "\n",
    "    kraftwerke[u'Type'] = kraftwerke[u\"Auswertung Energieträger\"].map({\n",
    "        u'Erdgas': u'Gas',\n",
    "        u'Grubengas': u'Gas',\n",
    "        u'Laufwasser': u'Run of River',\n",
    "        u'Pumpspeicher': u'Pumped Hydro',\n",
    "        u'Speicherwasser (ohne Pumpspeicher)': u'Storage Hydro',\n",
    "        u'Mineralölprodukte': u'Oil',\n",
    "        u'Steinkohle': u'Hard Coal',\n",
    "        u'Braunkohle': u'Brown Coal',\n",
    "        u'Abfall': u'Waste',\n",
    "        u'Kernenergie': u'Nuclear',\n",
    "        u'Sonstige Energieträger\\n(nicht erneuerbar) ': u'Other',\n",
    "        u'Mehrere Energieträger\\n(nicht erneuerbar)': u'Multiple',\n",
    "        u'Biomasse' : u'Biomass',\n",
    "        u'Deponiegas' : u'Gas',\n",
    "        u'Klärgas' : u'Gas',\n",
    "        u'Geothermie' : u'Geothermal',\n",
    "        u'Windenergie (Onshore-Anlage)' : u'Wind Onshore',\n",
    "        u'Windenergie (Offshore-Anlage)' : u'Wind Offshore',\n",
    "        u'Solare Strahlungsenergie' : u'Solar',\n",
    "        u'Unbekannter Energieträger\\n(nicht erneuerbar)' : u'Other'\n",
    "    })\n",
    "\n",
    "    return kraftwerke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_plants = read_kraftwerksliste()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_plants[power_plants[u\"Unternehmen\"] == \"EEG-Anlagen < 10 MW\"].groupby(u\"Type\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_plants.groupby(u\"Type\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#NB: bnetza extracted from BNetzA using\n",
    "\n",
    "#./Kraftwerksdaten.ipynb\n",
    "\n",
    "\n",
    "def backup_capacity_german_grid(G):   \n",
    "\n",
    "    from shapely.geometry import Point\n",
    "\n",
    "    plants = power_plants\n",
    "    plants = plants[plants[\"Kraftwerksstatus\"] == u\"in Betrieb\"]\n",
    "    \n",
    "    #remove EEG-receiving power plants - except biomass, these will be added later\n",
    "    \n",
    "    #it's necessary to remove biomass because we don't have coordinates for it\n",
    "    \n",
    "    for tech in [\"Solar\",\"Wind Onshore\",\"Wind Offshore\",\"Biomass\"]:\n",
    "        plants = plants[plants['Type'] != tech]\n",
    "    \n",
    "    cells = {n: d[\"region\"]\n",
    "             for n, d in G.nodes_iter(data=True)}\n",
    "\n",
    "    def nodeofaplant(x):\n",
    "        if np.isnan(x[\"lon\"]) or np.isnan(x[\"lat\"]):\n",
    "            return random.choice(list(cells.keys()))\n",
    "        p = Point(x[\"lon\"], x[\"lat\"])\n",
    "        for n, cell in iteritems(cells):\n",
    "            if cell.contains(p):\n",
    "                return n\n",
    "        else:\n",
    "            return min(cells, key=lambda n: cells[n].distance(p))\n",
    "    nodes = plants.apply(nodeofaplant, axis=1)\n",
    "\n",
    "    capacity = plants['Netto-Nennleistung'].groupby((nodes, plants[u'Type'])).sum() / 1e3\n",
    "    capacity.name = 'Capacity'\n",
    "\n",
    "    return capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = backup_capacity_german_grid(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.describe(),cap.sum(),type(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cap[pd.isnull(cap)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.fillna(0.1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap.index.levels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_costs = {\"Gas\" : 50.,\n",
    "           \"Brown Coal\" : 10.,\n",
    "           \"Hard Coal\" : 25.,\n",
    "           \"Oil\" : 100.,\n",
    "           \"Nuclear\" : 8.,\n",
    "           \"Pumped Hydro\" : 3.,\n",
    "           \"Storage Hydro\" : 3.,\n",
    "           \"Run of River\" : 3.,\n",
    "           \"Geothermal\" : 26.,\n",
    "           \"Waste\" : 6.,\n",
    "           \"Multiple\" : 28.,\n",
    "           \"Other\" : 32.}\n",
    "\n",
    "default_cost = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (bus_name,tech_name) in cap.index:\n",
    "    print(bus_name,tech_name,cap[(bus_name,tech_name)])\n",
    "    if tech_name == \"Pumped Hydro\":\n",
    "        network.add(\"StorageUnit\",bus_name + \" \" + tech_name,\n",
    "                bus=bus_name,p_nom=1000*cap[(bus_name,tech_name)],\n",
    "                marginal_cost=m_costs.get(tech_name,default_cost),\n",
    "                carrier=tech_name,\n",
    "                max_hours = 6,\n",
    "                efficiency_store=0.95,\n",
    "                efficiency_dispatch=0.95)\n",
    "    else:\n",
    "        network.add(\"Generator\",bus_name + \" \" + tech_name,\n",
    "                bus=bus_name,p_nom=1000*cap[(bus_name,tech_name)],\n",
    "                marginal_cost=m_costs.get(tech_name,default_cost),\n",
    "                carrier=tech_name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Add renewables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import generation.germany as DEgen\n",
    "\n",
    "reload(DEgen)\n",
    "\n",
    "generation = DEgen.timeseries_eeg(graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kill the Timezone information to avoid pandas bugs\n",
    "generation.major_axis = generation.major_axis.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation.loc[[\"wind\",\"solar\"],network.snapshots,:].sum(axis=2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar = generation.loc[\"solar\",network.snapshots,:].sum(axis=1)\n",
    "solar.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the ordering of the minor axis is correc\n",
    "generation.minor_axis = graph.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the capacities correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout = vresutils.reatlas.Cutout(cutoutname=\"Europe_2011_2014\", username=\"becker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def panel_capacity(panel):\n",
    "    \"\"\"\n",
    "    Returns the panel capacity in MW.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    panel : string\n",
    "        Panel name, e.g. \"Sunpower\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    capacity : float\n",
    "        In MW\n",
    "    \"\"\"\n",
    "    c = vresutils.reatlas.solarpanelconf_to_solar_panel_config_object(panel)\n",
    "    return c['A'] + c['B'] * 1000 + c['C'] * np.log(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_layouts = DEgen.eeg_solarlayouts(graph,cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_cap = panel_capacity(solar_layouts[0][\"panel\"])\n",
    "solar_caps = pd.Series(solar_layouts[1].sum(axis=(1,2))*panel_cap,\n",
    "                       graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_caps.describe(),solar_caps.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(generation.solar.max()/solar_caps).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windon_layouts = DEgen.eeg_windonlayouts_per_class(graph,cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windon_capacities = pd.DataFrame(index=graph.nodes())\n",
    "for turbine_items in windon_layouts:\n",
    "    name = turbine_items[0][\"onshore\"]\n",
    "    turbine_cap = np.array(vresutils.reatlas.turbineconf_to_powercurve_object(name)[\"POW\"]).max()\n",
    "    print(name,turbine_cap)\n",
    "    windon_capacities[name] = turbine_items[1].sum(axis=(1,2))*turbine_cap/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windon_caps = windon_capacities.sum(axis=1)\n",
    "windon_caps.describe(),windon_caps.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(generation.windon.max()/windon_caps).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windoff_layouts = DEgen.eeg_windofflayouts_per_class(graph,cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windoff_capacities = pd.DataFrame(index=graph.nodes())\n",
    "for i,turbine_items in enumerate(windoff_layouts):\n",
    "    name = turbine_items[0][\"offshore\"]\n",
    "    turbine_cap = np.array(vresutils.reatlas.turbineconf_to_powercurve_object(name)[\"POW\"]).max()\n",
    "    print(name,turbine_cap)\n",
    "    #add an index to name to avoid duplication of names\n",
    "    windoff_capacities[name+\"-\" + str(i)] = turbine_items[1].sum(axis=(1,2))*turbine_cap/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windoff_capacities.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windoff_caps = windoff_capacities.sum(axis=1)\n",
    "windoff_caps.describe(),windoff_caps.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(generation.windoff.max()/windoff_caps).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.plot(bus_sizes=1000*windoff_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.plot(bus_sizes=1000*windon_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.plot(bus_sizes=1000*solar_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = {\"windoff\" : {\"full_name\" : \"Wind Offshore\", \"caps\" : windoff_caps},\n",
    "    \"windon\" : {\"full_name\" : \"Wind Onshore\", \"caps\" : windon_caps},\n",
    "    \"solar\" : {\"full_name\" : \"Solar\", \"caps\" : solar_caps},\n",
    "     }\n",
    "\n",
    "for tech in [\"windoff\",'windon',\"solar\"]:\n",
    "    caps = d[tech][\"caps\"]\n",
    "    caps = caps[caps != 0]\n",
    "    \n",
    "    for i in caps.index:\n",
    "        network.add(\"Generator\",\"{} {}\".format(i,d[tech][\"full_name\"]),\n",
    "                    p_nom=caps[i]*1000.,dispatch=\"variable\",\n",
    "                    bus=i,carrier=d[tech][\"full_name\"],\n",
    "                    p_max_pu=generation[tech].loc[network.snapshots,i]/caps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder_name = \"../../lib/data/de_model/scigrid-with-load-gen-trafos\"\n",
    "\n",
    "network.export_to_csv_folder(csv_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.set_snapshots(network.snapshots[:24])\n",
    "\n",
    "csv_folder_name = \"../../lib/pypsa/examples/scigrid-de/scigrid-with-load-gen-trafos\"\n",
    "\n",
    "\n",
    "network.export_to_csv_folder(csv_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
